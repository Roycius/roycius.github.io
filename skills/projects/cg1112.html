<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"
        integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
    <link rel="stylesheet" href="/styles/info.css">
    <title>CG1112</title>
</head>

<body>
    <script id="navbar" src="/templates/navbar.js"></script>

    <div class="container">
        <h1 class="text-dark m-2 p-2 text-center">CG1112 Engineering Principles and Practice II</h1>
        <blockquote class="blockquote bg-light m-2 p-3">
            <p>This module will be for the students who have completed EPP I and the project scope extends to handle
                challenges in large-scale systems. Similar to EPP I, students will first learn the fundamental
                principles on certain advanced concepts and then design and programme a real-world system. The module
                involves designing a complex computer engineering system that facilitates information processing,
                real-world interfacing, and understanding the effects of certain useful metrics such as, scaling,
                safety, security, sustainability, societal impact, fault-tolerant design, etc.</p>
            <footer class="blockquote-footer">Module description at <cite title="Source Title">NUSMods</cite></footer>
        </blockquote>
    </div>

    <div class="container">
        <h2 class="border-bottom border-dark py-2">Abstract</h2>
        <p>In this module, we formed a team of 4 to design and build a rescue bot. The rescue bot's movements are
            controlled by sending commands through wireless serial communication to a Raspberry Pi, which then instructs
            the Arduino Uno to power the 2 motor wheels to move according to the instructions. By using ROS as a
            middleware, the Lidar above the bot constantly scans the environment a relays readings to the Raspberry Pi,
            which in turn allows us to generate a map of the surrounding maze. Additionally an Ultrasonic sensor is
            integrated to prevent collision, and a color sensor to allow the bot to detect and relay information
            regarding the color of objects in front of the bot to the controller.</p>

        <h2 class="border-bottom border-dark py-2">Skills Learnt</h2>
        <ul>
            <li>C Programming on Arduino Uno</li>
            <li>Working with Ultrasonic and Color Sensor</li>
            <li>Using LiDAR with ROS</li>
            <li>Remote Serial Communication to Raspberry Pi</li>
            <li>Working with Raspberry Pi</li>
        </ul>

        <h2 class="border-bottom border-dark py-2">Relevant Links</h2>
        <ul>
            <li><a href="https://docs.google.com/document/d/1KtAUsqBP18o5zEAsitiPSrKYOyhNdEKHF45jAsDwoBw">Design report
                    for the project</a></li>
        </ul>

    </div>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct"
        crossorigin="anonymous"></script>

</body>

</html>